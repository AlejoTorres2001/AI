{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import CTransformers\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_llm():\n",
    "    llm = CTransformers(\n",
    "        model='llama-2-7b-chat.ggmlv3.q8_0.bin',\n",
    "        model_type='llama',\n",
    "        max_new_token=512,\n",
    "        temperature=0.5\n",
    "    )\n",
    "    return llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval_qa_chain(llm, prompt, db: FAISS):\n",
    "    qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                           chain_type='stuff',\n",
    "                                           retriever=db.as_retriever(\n",
    "                                               search_kwargs={'k': 3}),\n",
    "                                           return_source_documents=True,\n",
    "                                           chain_type_kwargs={\"verbose\": True, \"prompt\": prompt,\n",
    "                                                              }\n",
    "                                           )\n",
    "    return qa_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_custom_conversational_prompts():\n",
    "    condense_prompt = PromptTemplate.from_template(\n",
    "        ('Do X with user input ({question}), and do Y with chat history ({chat_history}).')\n",
    "    )\n",
    "\n",
    "    combine_docs_custom_prompt = PromptTemplate.from_template(\n",
    "        ('Write a haiku about a dolphin.\\n\\n'\n",
    "         'Completely ignore any context, such as {context}, or the question ({question}).')\n",
    "    )\n",
    "    return condense_prompt, combine_docs_custom_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conversational_retrieval_chain(llm, db: FAISS):\n",
    "    condense_prompt, combine_docs_custom_prompt = set_custom_conversational_prompts()\n",
    "\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\",\n",
    "        return_messages=True,)\n",
    "\n",
    "    chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=db.as_retriever(search_kwargs={'k': 2}),\n",
    "        memory=memory,\n",
    "        condense_question_prompt=condense_prompt,\n",
    "        verbose=True,\n",
    "        combine_docs_chain_kwargs=dict(prompt=combine_docs_custom_prompt)\n",
    "    )\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_PATH = \"./vectorstores/db_faiss\"\n",
    "def qa_bot():\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs={'device': 'cpu'})\n",
    "\n",
    "    db = FAISS.load_local(folder_path=DB_PATH, embeddings=embeddings)\n",
    "\n",
    "    llm = load_llm()\n",
    "\n",
    "    qa = conversational_retrieval_chain(llm=llm,db=db)\n",
    "    return qa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell contais an example with an alterated condense and combine docs prompts that make the model ignore the chat history and context completely, instead it is forced to make a japanese poem about dolphins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\torre\\.virtualenvs\\llama-medical-bot-or6BXnwr\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\torre\\.virtualenvs\\llama-medical-bot-or6BXnwr\\Lib\\site-packages\\bitsandbytes\\cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a haiku about a dolphin.\n",
      "\n",
      "Completely ignore any context, such as Nancy Ross-Flanigan\n",
      "Antidiabetic drugs\n",
      "Definition\n",
      "Antidiabetic drugs are medicines that help control\n",
      "blood sugar levels in people with diabetes mellitus\n",
      "(sugar diabetes).\n",
      "Purpose\n",
      "Diabetes may be divided into type I and type II, for-\n",
      "merly termed juvenile onset or insulin-dependent, and\n",
      "GALE ENCYCLOPEDIA OF MEDICINE 2 261Antidiabetic drugsGEM - 0001 to 0432 - A  10/22/03 1:42 PM  Page 261\n",
      "\n",
      "andpermit glucose control over longer periods of time., or the question (What is the treatment for diabetes?).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'question': 'What is the treatment for diabetes?', 'chat_history': [HumanMessage(content='What is the treatment for diabetes?', additional_kwargs={}, example=False), AIMessage(content=\" Instead, focus on a specific aspect of dolphins. Here's my attempt at a haiku about a dolphin:\\n\\nDolphin swims blue sea\\nGraceful leaps in ocean waves\\nBeauty to behold\", additional_kwargs={}, example=False)], 'answer': \" Instead, focus on a specific aspect of dolphins. Here's my attempt at a haiku about a dolphin:\\n\\nDolphin swims blue sea\\nGraceful leaps in ocean waves\\nBeauty to behold\"}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(qa_bot()({'question': \"What is the treatment for diabetes?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will work with coherent prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_custom_conversational_prompts():\n",
    "    condense_prompt = PromptTemplate.from_template(\n",
    "        ('Answer the question ({question}), use the chat history ({chat_history}) to infer valuable information to formulate a complete answer.')\n",
    "    )\n",
    "\n",
    "    combine_docs_custom_prompt = PromptTemplate.from_template(\n",
    "        (\"\"\"You are a helpful, medical assistant.If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. Use the following pieces of information to answer the user's question.\n",
    "        \n",
    "        Context: {context}\n",
    "        \n",
    "        Question: {question}\n",
    "Only return the helpful answer below and nothing else.Helpful answer:\n",
    "        \"\"\")\n",
    "    )\n",
    "    return condense_prompt, combine_docs_custom_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\torre\\.virtualenvs\\llama-medical-bot-or6BXnwr\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\torre\\.virtualenvs\\llama-medical-bot-or6BXnwr\\Lib\\site-packages\\bitsandbytes\\cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a helpful, medical assistant.If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. Use the following pieces of information to answer the user's question.\n",
      "        \n",
      "        Context: Nancy Ross-Flanigan\n",
      "Antidiabetic drugs\n",
      "Definition\n",
      "Antidiabetic drugs are medicines that help control\n",
      "blood sugar levels in people with diabetes mellitus\n",
      "(sugar diabetes).\n",
      "Purpose\n",
      "Diabetes may be divided into type I and type II, for-\n",
      "merly termed juvenile onset or insulin-dependent, and\n",
      "GALE ENCYCLOPEDIA OF MEDICINE 2 261Antidiabetic drugsGEM - 0001 to 0432 - A  10/22/03 1:42 PM  Page 261\n",
      "\n",
      "andpermit glucose control over longer periods of time.\n",
      "        \n",
      "        Question: What is the treatment for diabetes?\n",
      "Only return the helpful answer below and nothing else.Helpful answer:\n",
      "        \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'question': 'What is the treatment for diabetes?', 'chat_history': [HumanMessage(content='What is the treatment for diabetes?', additional_kwargs={}, example=False), AIMessage(content=\"\\nThe treatment for diabetes involves a combination of lifestyle modifications and medication. Lifestyle modifications include:\\nmaintaining a healthy diet, regular exercise, weight loss if overweight or obese, quitting smoking, and limiting alcohol intake. Medications used to treat diabetes include:\\n* Metformin (Glucophage) - works by increasing the body's sensitivity to insulin\\n* Sulfonylureas (such as glyburide or glipizide) - stimulate the release of insulin from the pancreas\\n* Thiazolidinediones (such as pioglitazone) - increase the body's sensitivity to insulin and improve glucose uptake in the cells\\n* Dipeptidyl peptidase-4 (DPP-4) inhibitors (such as sitagliptin or saxagliptin) - increase the amount of insulin produced by the body, decrease the amount of glucose produced by the liver.\\nIt is there are just to be taken alone oralcoordinar\\nPlease note: It'Antidiop\", additional_kwargs={}, example=False)], 'answer': \"\\nThe treatment for diabetes involves a combination of lifestyle modifications and medication. Lifestyle modifications include:\\nmaintaining a healthy diet, regular exercise, weight loss if overweight or obese, quitting smoking, and limiting alcohol intake. Medications used to treat diabetes include:\\n* Metformin (Glucophage) - works by increasing the body's sensitivity to insulin\\n* Sulfonylureas (such as glyburide or glipizide) - stimulate the release of insulin from the pancreas\\n* Thiazolidinediones (such as pioglitazone) - increase the body's sensitivity to insulin and improve glucose uptake in the cells\\n* Dipeptidyl peptidase-4 (DPP-4) inhibitors (such as sitagliptin or saxagliptin) - increase the amount of insulin produced by the body, decrease the amount of glucose produced by the liver.\\nIt is there are just to be taken alone oralcoordinar\\nPlease note: It'Antidiop\"}\n"
     ]
    }
   ],
   "source": [
    "print(qa_bot()({'question': \"What is the treatment for diabetes?\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] <<SYS>>\n",
      "You are a helpful, respectful and honest medical assistant.Use the following pieces of information to answer the user's question.If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
      "    Use the following pieces of information to answer the user's question.\n",
      "\n",
      "    Context: {context}\n",
      "    Question: {question}\n",
      "\n",
      "    Only return the helpful answer below and nothing else.\n",
      "    Helpful answer:\n",
      "    \n",
      "<</SYS>>\n",
      "\n",
      "User_Msg_1 [/INST] Asst_Msg_1 </s><s>[INST] User_Msg_2 [/INST] Asst_Msg_2 </s><s>[INST] User_Msg_3 [/INST]\n"
     ]
    }
   ],
   "source": [
    "def llama_v2_prompt(\n",
    "    messages: list[dict]\n",
    "):\n",
    "    B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "    B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "    BOS, EOS = \"<s>\", \"</s>\"\n",
    "    DEFAULT_SYSTEM_PROMPT = \"\"\"You are a helpful, respectful and honest medical assistant.Use the following pieces of information to answer the user's question.If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
    "    Use the following pieces of information to answer the user's question.\n",
    "\n",
    "    Context: {context}\n",
    "    Question: {question}\n",
    "\n",
    "    Only return the helpful answer below and nothing else.\n",
    "    Helpful answer:\n",
    "    \"\"\"\n",
    "\n",
    "    if messages[0][\"role\"] != \"system\":\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": DEFAULT_SYSTEM_PROMPT,\n",
    "            }\n",
    "        ] + messages\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": messages[1][\"role\"],\n",
    "            \"content\": B_SYS + messages[0][\"content\"] + E_SYS + messages[1][\"content\"],\n",
    "        }\n",
    "    ] + messages[2:]\n",
    "\n",
    "    messages_list = [\n",
    "        f\"{BOS}{B_INST} {(prompt['content']).strip()} {E_INST} {(answer['content']).strip()} {EOS}\"\n",
    "        for prompt, answer in zip(messages[::2], messages[1::2])\n",
    "    ]\n",
    "    messages_list.append(\n",
    "        f\"{BOS}{B_INST} {(messages[-1]['content']).strip()} {E_INST}\")\n",
    "\n",
    "    return \"\".join(messages_list)\n",
    "\n",
    "\n",
    "message = llama_v2_prompt(\n",
    "    [\n",
    "        {'role': 'user', 'content': 'User_Msg_1'},\n",
    "        {'role': 'assistant', 'content': 'Asst_Msg_1'},\n",
    "        {'role': 'user', 'content': 'User_Msg_2'},\n",
    "        {'role': 'assistant', 'content': 'Asst_Msg_2'},\n",
    "        {'role': 'user', 'content': 'User_Msg_3'}]\n",
    ")\n",
    "print(message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-medical-bot-or6BXnwr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
